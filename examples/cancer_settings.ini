[general]
verbose = True
gpu = False
seed = 792
conserve_memory = True
model_type = classifier
label = target
data_to_use = train_test
compute_hyperparameters = True
naming_classes = model, cleaver

[files]
file_encoding = windows-1252
float_format = %.4f
test_data = True
test_chunk = 500
use_seed_test_chunk = True
boolean_out = True
source_format = csv
interim_format = csv
final_format = csv
results_format = csv

[cookbook]
cookbook_steps = scaler, splitter, encoder, mixer, cleaver, sampler, reducer, model
scaler = normalizer
splitter = stratified
encoder = target
mixer = polynomial
cleaver = none
sampler = smote
reducer = none
model = xgb
metrics = roc_auc, f1, accuracy, balanced_accuracy, brier_score_loss, hamming, jaccard, neg_log_loss, matthews_corrcoef, precision, recall, zero_one
search_algorithm = random
export_all_recipes = True

[scaler]
copy = False
encode = ordinal
strategy = uniform
threshold = 1

[splitter]
test_size = 0.33
val_size = 0
n_splits = 5
shuffle = False

[encoder]

[mixer]

[cleaver]
include_all = True
prefixes = True

[sampler]
sampling_strategy = auto

[reducer]
n_features_to_select = 10
step = 1
score_func = f_classif
alpha = 0.05
threshold = mean

[model]

[search_parameters]
n_iter = 20
scoring = roc_auc, f1, neg_log_loss
cv = 5
refit = True

[random_forest]
n_estimators = 20, 1000
max_depth = 5, 30
max_features = 10, 50
max_leaf_nodes = 5, 10
bootstrap = True
oob_score = True
verbose = 0

[xgb]
booster = gbtree
objective = binary:logistic
eval_metric = aucpr
silent = True
n_estimators = 50, 500
max_depth = 3, 30
learning_rate = 0.001, 1.0
subsample = 0.2, 0.8
colsample_bytree = 0.2, 0.8
colsample_bylevel = 0.2, 0.8
min_child_weight = 0.5, 1.5
gamma = 0.0, 0.1
alpha = 0.0, 1

[baseline_classifier]
strategy = most_frequent

[review]
evaluator_options = default
prediction_method = gini
join_predictions = True
probability_method = gini
join_pred_probs = True
importance_methods = shap, permutation
explainers = shap
data_to_explain = test
shap_model_output = probability

[presentation]
presentation_options = default
data_to_plot = test
custom_plots = none
plt_style = fivethirtyeight
plt_font = Franklin Gothic Book
seaborn_style = darkgrid
seaborn_context = paper
seaborn_palette = dark
interactions_display = 10
features_display = 20
summary_display = 20
dependency_plots = carvers, top_features
shap_plot_type = dot
comparison_plots = False